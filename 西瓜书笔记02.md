# 西瓜书笔记02

## 第二章 模型的评估与选择

### 2.1 经验误差与过拟合T

![屏幕截图 2025-08-18 214826](d:\Users\秦喜\Desktop\屏幕截图 2025-08-18 214826.png)

**模型选择的三个关键问题：**

1. 如何获得测试结果？         评估方法
2. 如何评估性能优劣？         性能度量
3. 如何判断实质差别？         比较检验

### 2.2 评估方法

在现实任务中，我们往往有多种算法可供选择，那么我们应该选择哪一个算法才是最适合的呢？如上所述，我们希望得到的是泛化误差小的学习器，理想的解决方案是对模型的泛化误差进行评估，然后选择泛化误差最小的那个学习器。但是，泛化误差指的是模型在所有新样本上的适用能力，我们无法直接获得泛化误差。
因此，通常我们采用一个"测试集"来测试学习器对新样本的判别能力，然后以"测试集"上的"测试误差"作为"泛化误差"的近似。显然：**我们选取的测试集应尽可能与训练集互斥**，下面用一个小故事来解释why:
假设老师出了10道习题供同学们练习，考试时老师又用同样的这10道题作为试题；可能有的童鞋只会做这10道题却能得高分，很明显：这个考试成绩并不能有效地反映出真实水平。回到我们的问题上来，我们希望得到泛化性能好的模型，好比希望同学们课程学得好并获得了对所学知识"举一反三"的能力；训练样本相当于给同学们练习的习题，测试过程则相当于考试。显然，若测试样本被用作训练了，则得到的将是过于"乐观"的估计结果。

### 2.3 训练集与测试集的划分方法

**1.留出法**

它把全部数据（可以理解为一个总体）随机地划分成两个互斥的集合，一个集合用来训练模型，称为训练集；另一个集合用来测试训练好的模型，称为测试集。
通过模型在测试集上的表现，来推断模型在总体数据上的性能。（常见的划分比例为：7:3或者8:2）

**注意事项：**

1. 保持数据分布的一致性（例如：分层采样）    分层采样按照数据的某些特征或类别进行分层，然后在每一层中进行随机采样，使得训练集和测试集中各类别或特征的比例与原始数据集大致相同
2. 多次重复划分(例如:100次随机划分)    避免因单次划分的随机性而产生偏差，通过综合分析多次划分得到的结果，比如计算平均值、标准差等统计量，以更稳定地评估模型的性能。 
3. 测试集不能太大、不能太小    太大或者太小，模型无法充分学习数据中的规律

**2.k - 折交叉验证法**

![微信图片_20250819200141](d:\Users\秦喜\Desktop\微信图片_20250819200141.jpg)

将数据集随机划分为 k 等份，轮流用 k - 1 份训练模型、1 份测试模型，最终取 k 次测试结果的平均，用于评估模型泛化能力 。

**留一法（Leave-One-Out，简称 LOO）（k=m）**

操作步骤：

1. 数据划分：数据集有 m 个样本，将每个样本依次单独作为验证集，其余 m − 1 个样本构成训练集，共 m种划分。
2. 模型训练与测试：针对每种划分去训练模型，并用对应验证集样本测试，记录模型性能。
3. 结果汇总：重复上述过程，待每个样本都做过一次验证集后，汇总 m 次测试结果，计算平均误差或其他性能度量值。

**k - 折交叉验证法的特例“留一法”和“留出法”的区别**

**本质区别：数据利用方式、模型训练验证方式不同**

数据划分：
     留一法：每次以一个样本作为验证集，其余样本为训练集，数据集有 m 个样本就有 m 种划分
     留出法：随机将数据分成训练集和测试集，测试集包含多个样本。
计算成本：
    留一法：需训练 m 次模型，计算开销大
    留出法：仅训练一次模型，计算成本低 
评估准确性：
     留一法：每次训练几乎利用了全部数据训练，模型的偏差（bias）会比较小。但因为测试集只有一个样本，所以每次评估结果的波动较大（方差较大）。
     留出法：受不同划分方式的影响，结果波动 

**3.自助法**

![微信图片_20250819202544](d:\Users\秦喜\Desktop\微信图片_20250819202544.jpg)

我们希望评估的是用整个D训练出的模型。但在留出法和交叉验证法中，由于保留了一部分样本用于测试，因此实际评估的模型所使用的训练集比D小，这必然会引入一些因训练样本规模不同而导致的估计偏差。留一法受训练样本规模变化的影响较小，但计算复杂度又太高了。"自助法"正是解决了这样的问题。
自助法的基本思想是：给定包含m个样本的数据集D，每次随机从D 中挑选一个样本，将其拷贝放入D'，然后再将该样本放回初始数据集D中，使得该样本在下次采样时仍有可能被采到。重复执行m 次，就可以得到了包含m个样本的数据集D'。

这样，h通过自助采样，初始样本集D中大约有36.8％的样本没有出现在D'中，于是可以将D'作为训练集，D-D'作为测试集。自助法在数据集较小，难以有效划分训练集／测试集时很有用，但由于自助法产生的数据集（随机抽样）改变了初始数据集的分布，因此引入了估计偏差。在初始数据集足够时，留出法和交叉验证法更加常用。

###  2.4 调参

1. 参数分类

- 算法参数：一般由人为设定，也叫 “超参数” 。

- 模型参数：一般通过学习确定 。

  2.调参过程：先产生若干模型，再基于某种评估方法进行选择。

  3.参数重要性：参数调整的优劣对模型最终性能有关键影响。

  4.数据集区别：涉及**训练集、测试集、验证集（validation set）** 。

  5.模型训练：选定算法参数后，需用 “训练集 + 验证集” 重新训练最终模型。

### 2.5 性能度量

 性能度量(performance measure)是<u>衡量模型泛化能力的评价标准，反映了任务需求。</u>使用不同的性能度量往往会导致不同的评判结果。
<u>什么样的模型是“好”的，不仅取决于算法和数据，还取决于任务需求。</u>

### 